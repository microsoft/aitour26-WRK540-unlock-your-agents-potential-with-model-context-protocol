# 架构概述

## 核心技术一览

- **Azure AI Foundry 代理服务**
  托管 LLM 驱动的代理；编排工具（包括 MCP 服务器）；管理上下文、代码解释器和令牌流传输；提供身份验证、日志记录和扩展功能。
- **MCP 服务器**
  MCP（模型上下文协议）是一个开放标准，为 LLM 提供统一的外部工具、API 和数据接口。它标准化了工具发现（类似于 REST 的 OpenAPI），通过使工具易于更新或交换来提高可组合性。
- **PostgreSQL + pgvector**
  存储关系数据和嵌入向量；支持关系型（SQL）和语义型（向量）查询（通过 pgvector），由 SQL 和 RLS 管理。

**协同工作**：代理服务路由用户意图；MCP 服务器将其转换为工具/SQL 调用；PostgreSQL+pgvector 回答语义和分析问题。

## 架构（高层次）

```plaintext
┌─────────────────────┐                         ┌─────────────────┐
│   Zava 代理应用     │       stdio/https       │   MCP 服务器    │
│   (app.py)          │◄───────────────────────►│ (sales_analysis)│
│                     │      MCP 传输协议        └─────────────────┘
│ ┌─────────────────┐ │                                 │
│ │ Azure AI        │ │                                 ▼
│ │ 代理服务        │ │                         ┌─────────────────┐
│ │ + 流式传输      │ │                         │ Azure Database  │
│ │                 │ │                         │ for PostgreSQL  │
│ └─────────────────┘ │                         │   + pgvector    │
└─────────────────────┘                         └─────────────────┘
         │                                              |
         ▼                                              ▼
┌─────────────────────┐                         ┌─────────────────┐
│ Azure OpenAI        │                         │ Zava 销售       │
│ 模型部署            │                         │ 数据库与        │
│ - gpt-4o-mini       │                         │ 语义搜索        │
│ - text-embedding-3- │                         └─────────────────┘
│   small             │
└─────────────────────┘
```

## MCP 服务器的主要优势

- **互操作性** – 将 AI 代理连接到任何供应商支持 MCP 的工具，只需最少的自定义代码。
- **安全钩子** – 集成登录、权限和活动日志记录。
- **可重用性** – 构建一次，在项目、云和运行时之间重复使用。
- **操作简单性** – 单一合约减少样板代码和维护工作。

## 演示的最佳实践

- **异步 API**：代理服务和 PostgreSQL 使用异步 API；非常适合 FastAPI/ASP.NET/Streamlit。
- **令牌流式传输**：改善 UI 中的感知延迟。
- **可观测性**：内置跟踪和指标支持监控和优化。
- **数据库安全**：PostgreSQL 通过受限的代理权限和行级安全性 (RLS) 进行保护，将代理限制为仅访问其授权数据。
- **代码解释器**：[Azure AI 代理服务代码解释器](https://learn.microsoft.com/azure/ai-services/agents/how-to/tools/code-interpreter?view=azure-python-preview&tabs=python&pivots=overview){:target="_blank"} 在**沙盒**环境中按需运行 LLM 生成的代码，防止超出代理范围的操作。

### 可扩展性

工作坊模式可以通过更新 Foundry 中的数据库 + 代理指令进行适配（例如，客户支持）。

## DevTunnel 架构

在工作坊环境中，代理服务在 Azure 中运行，但需要连接到本地运行的 MCP 服务器。DevTunnel 创建一个安全隧道，将本地 MCP 服务器暴露给基于云的代理服务。

```plaintext
          Azure Cloud                           Local Development
    ┌─────────────────────┐                  ┌─────────────────────┐
    │   Zava 代理应用     │                  │                     │
    │   (Azure 托管)      │                  │  ┌─────────────────┐│
    │                     │                  │  │   MCP 服务器    ││
    │ ┌─────────────────┐ │                  │  │ (sales_analysis)││
    │ │ Azure AI        │ │                  │  │ localhost:8000  ││
    │ │ 代理服务        │ │                  │  └─────────────────┘│
    │ └─────────────────┘ │                  │           │         │
    └─────────────────────┘                  │           ▼         │
              │                              │  ┌─────────────────┐│
              │ HTTPS 请求                   │  │   PostgreSQL    ││
              ▼                              │  │   + pgvector    ││
    ┌─────────────────────┐                  │  └─────────────────┘│
    │   DevTunnel         │                  │                     │
    │   公共端点          │◄─────────────────┼──── 安全隧道        │
    │ (*.devtunnels.ms)   │    端口转发      │                     │
    └─────────────────────┘                  └─────────────────────┘
```

**DevTunnel 在工作坊中的工作方式**：

1. **本地开发**：您在 `localhost:8000` 本地运行 MCP 服务器
2. **DevTunnel 创建**：DevTunnel 创建一个连接到 `localhost:8000` 的公共 HTTPS 端点（例如，`https://abc123.devtunnels.ms`）。
3. **Azure 集成**：Azure 托管的代理服务通过 DevTunnel 端点连接到 MCP 服务器。
4. **透明操作**：代理服务正常运行，不知道它正在通过隧道访问本地运行的 MCP 服务器。

此设置允许您：

- 在使用云托管 AI 服务时进行本地开发和调试
- 无需将 MCP 服务器部署到 Azure 即可测试真实场景

*使用 GitHub Copilot 翻译。*
